---
title: "ENHANCED ACOUSTIC TAGGING, ANALYSIS, AND REAL-TIME MONITORING OF WILD AND
  HATCHERY SALMONIDS IN THE SACRAMENTO RIVER VALLEY"
params:
  printcode: no
  begindate: "October 1, 2022"
  enddate: "March 31, 2023"
author: "Semi-annual report `r params$begindate` to `r params$enddate`"
output:
  word_document:
    reference_docx: template.docx
    toc: yes
    toc_depth: '1'
    fig_caption: yes
  html_document:
    toc: yes
    toc_depth: '1'
    df_print: paged
  pdf_document:
    toc: yes
    toc_depth: '1'
    fig_caption: yes
always_allow_html: yes
---

```{r setup, include=FALSE, class.source = 'fold-hide'}
knitr::opts_chunk$set(echo = params$printcode, message = FALSE)
knitr::opts_knit$set(root.dir = '/Volumes/JRFREY_NOAA/SemiAnnReport/report2')

# load data access packages
library(odbc) #Read in Access database off of SQL server
library(dataRetrieval)
library(rerddap)
library(dbplyr)
library(DBI) #R database management
#load data manip packages
library(data.table)
library(tidyverse)
library(fs)
library(lubridate)
#load report generation packages
#install.packages(rmarkdown)
library(shiny)
library(rmarkdown) #generate word report
#install.packages(knitr)
library(knitr) #generate word report
#install.packages(flextable)
library(flextable) #format tables
#install.packages("officer") #format tables
library(officer)

#set border style first time
bord = fp_border(color="#9bb4df", width=1)

#store and format date params
begindatechar<- params$begindate
begindate<- lubridate::mdy(params$begindate)
enddatechar<- params$enddate
enddate<- mdy(params$enddate)
```

Prepared for:\
United States Bureau of Reclamation\
Cooperative Agreement R21AC10455

Principal Investigator:\
Cyril Michel\
University of California, Santa Cruz\
Associated with\
NOAA Southwest Fisheries Science Center\
Fisheries Ecology Division\
110 McAllister Way\
Santa Cruz CA 95060\
[cyril.michel\@noaa.gov](mailto:cyril.michel@noaa.gov){.email}

Technical Point of Contact:\
Jeremy Notch\
University of California, Santa Cruz\
Associated with\
NOAA Southwest Fisheries Science Center\
Fisheries Ecology Division\
110 McAllister Way\
Santa Cruz CA 95060\
[jeremy.notch\@noaa.gov](mailto:jeremy.notch@noaa.gov){.email}

\newpage

\tableofcontents

\newpage

# Introduction

This report summarizes the fieldwork, data collection, and analysis performed by UC Santa Cruz (UCSC) between October 1 and March 31, 2023, as part of the Cooperative Agreement R21AC10455 between the US Bureau of Reclamation (USBR) and UCSC. This is the third semi-annual report for the Cooperative Agreement R21AC10455, extending from October 1, 2021 to September 30, 2026. This semi-annual report outlines deliverables for the six tasks described by the agreement.

```{r callr, include=FALSE}
##Table 1. Location of real-time JSATS receivers with the date first operational in real-time

con <- dbConnect(odbc(),
                    Driver = "ODBC Driver 17 for SQL Server",
                    Server = "calfishtrack-server.database.windows.net",
                    Database = "JSATS_Database",
                    UID = "jsats_user",
                    PWD = "Pass@123",
                    Port = 1433)
odbcListObjects(con)

```

# Task 1. Deploy real-time array of JSATS receivers

```{r callrt, echo = FALSE}
##Table 1. Location of real-time JSATS receivers with the date first operational in real-time

#call receiver deployment table
Rec_Dep<-dbReadTable(con, "ReceiverDeployments")

#remove NA and 999 named receivers
Rec_Dep2<- Rec_Dep[!is.na(Rec_Dep$GPSname), ]
Rec_Dep2<- Rec_Dep2[Rec_Dep2$GPSname != "999", ]

#create start date col
Rec_Dep2$StartDate<-as.Date(Rec_Dep2$StartTime,format = "%Y-%m-%d", optional=T)
#create end date col
Rec_Dep2$EndDate<-as.Date(Rec_Dep2$EndTime, format = "%Y-%m-%d", optional=T)

#Get deployments in range interested in
start<-Rec_Dep2[Rec_Dep2$StartDate >= begindate,]
#this is the end date for period of interest
start2<-start[start$StartDate <= enddate,]

#grab receivers ended in period of interest
end<- Rec_Dep2[Rec_Dep2$EndDate >= begindate,]
end2<-end[end$EndDate <= enddate,]

#grab receivers still active
notend<- Rec_Dep2[is.na(Rec_Dep2$EndDate), ]
notend<- notend[notend$StartDate >= begindate, ]

#Make sure GPS names match
Rec_Dep3<-unique(rbind(start2, end2, notend))
#remove NA receiver name brought in from date filters
Rec_Dep3<- Rec_Dep3[!is.na(Rec_Dep3$GPSname), ]

#read in receiver locations table
Rec_Loc<-dbReadTable(con, "ReceiverLocations")
#remove 999 named location
Rec_Loc<- Rec_Loc[Rec_Loc$GPSname != "999", ]

#test Loc name matches
test<- left_join(Rec_Dep3, Rec_Loc, by="GPSname")
notmatches<- as.data.frame(which(is.na(test$GeneralLocation), arr.ind=TRUE))
#show not matches
notmatches1 <- filter(Rec_Dep3, row_number() %in% notmatches$`which(is.na(test$GeneralLocation), arr.ind = TRUE)`)
#Meridian is spelled wrong
Rec_Dep3$GPSname<- gsub("Meridan", "Meridian", Rec_Dep3$GPSname)

#Review coverage for descriptive summary
######################################################################################
#find sites with multiple deployments
dupes <- Rec_Dep3[duplicated(Rec_Dep3$GPSname),]
#select all multiple deployments
redeploys<- filter(Rec_Dep3, GPSname %in% dupes$GPSname)
redeploys<- redeploys %>% 
          arrange(GPSname, StartTime) %>% 
          summarise(GPSname, StartTime, DataCoverage, CoverageProblem,
                    RecDeployNotes)
######################################################################################

#select receiver location columns
Rec_Loc2<-subset(Rec_Loc, select = c("GeneralLocation","rkm", "GPSname", "Region", "Lat", "Lon"))
#join receiver deployments and receiver locations 
Rec_Dep4<-unique(merge(Rec_Dep3,Rec_Loc2, all.x=TRUE))
#reorder columns
Rec_Dep5<-Rec_Dep4[,c("Region","GPSname","Lat","Lon","rkm","RecMake","SN","StartTime","EndTime")]
#remove comma from SN
Rec_Dep5$SN<- as.character(Rec_Dep5$SN)
#remove row numbers
rownames(Rec_Dep5) <- c()

#Select real-time receivers
Rec_Dep6<-Rec_Dep5[which(Rec_Dep5$RecMake=="ATS SR3017" | Rec_Dep5$RecMake=="ATS 3017" |
                           Rec_Dep5$RecMake=="Tekno RT" | Rec_Dep5$RecMake=="Tekno" |
                           is.na(Rec_Dep5$RecMake)),]

#Order table by StartTime
Rec_Dep6<- Rec_Dep6[order(as.Date(Rec_Dep6$StartTime, format="%d-%m-%Y")),]

#Count real-time receivers by Region
regs0<- dplyr::count(unique(Rec_Dep6),Region)

#### may need to be updated
sac<- regs0[str_detect(regs0$Region, '^.*Sac'),]
sac<- sac$n
#delta <- regs0[str_detect(regs0$Region, '^.*Delta'), ]
#delta<- sum(delta$freq)
# gg <- regs0[str_detect(regs0$Region, 'SF Bay'), ]
# gg<- gg$n
#mc<- subset(regs0, regs0$Region=='Mill Ck')
#mc<- mc$n
#sj<- subset(regs0, regs0$Region=='SanJoaquin_R')
#sj<- sj$n
cs<- subset(regs0, regs0$Region=='Carquinez Strait')
cs<- cs$n

```

There were `r nrow(Rec_Dep6)` real-time receivers deployed and/or retrieved during this quarter (Table 1). All acoustic receivers stationed in the Lower Sacramento River (`r sac`) and Carquinez Straight (`r cs`) were retrieved and deployed by UCSC.

All real-time receivers shown in Table 1 were operational during this quarter, except for temporary receiver outages due to SD card failure, modem disconnect, and interruptions to power resulting from a stolen battery (Tower Bridge, I80 Bridge) and loose wiring. Butte Bridge receivers were removed due to bridge replacement by Caltrans. Site visits were conducted at all locations for quarterly data downloads, maintenance, and SD card swaps. Maintenance for the instruments included updating firmware, replacing a receiver, and installing new batteries in locked job boxes to prevent future theft.

A detailed spreadsheet of all real-time receiver deployments can be found here: <https://docs.google.com/spreadsheets/d/1oBfEO3cIdP9PJaLxyN9kJ2yYpufTfGIIDvBtVnU8muo/edit#gid=79918077>

```{r table1, echo=FALSE}

#pipe data to table and give caption
RecDep6<- Rec_Dep6%>%
  flextable() %>%
    set_caption(caption = "Table 1. Location of real-time JSATS receivers deployed during this report period with the date first operational in real-time")%>%
    font(fontname = "Times New Roman", part = "all") %>% 
    fontsize(size = 11, part = "body")%>%
    width(width = .75)

#set table style
RecDep6<- theme_zebra(RecDep6, odd_header="#4472c4", odd_body ="#d9e2f3", even_header="transparent", even_body="transparent")
RecDep6<- border_outer(RecDep6, part="all", border= bord)
RecDep6<- border_inner(RecDep6, part="body", border=bord)
RecDep6<- align(RecDep6, align = "center", part = "all")


#print table
RecDep6

```

Deliverables 1-4 were met by posting data relating to survival and movement to the website: <https://oceanview.pfeg.noaa.gov/CalFishTrack>

## Deliverables

1.  Web-accessible reporting status of real-time receivers
2.  Real-time data available through ERDDAP data server, updated daily
3.  Web-accessible real-time receiver data available in open data format
4.  Web-accessible summary database of deployment of receivers
5.  Data quality assurance of no more than 3 days of downtime before a site visit to reestablish real-time operations
6.  Provide a semi-annual compiled raw data file for each real-time receiver along with deployment metadata to Arnold Ammann (NMFS)

# Task 2. Deploy autonomous array of JSATS and Vemco receivers

## Autonomous Receiver Deployment

```{r callat, echo=FALSE}
##Table 2. Autonomous JSATS receivers active, deployed, or retrieved between October 1, 2022, and March 31, 2023

#Collect autonomous JSATS
#Select real-time receivers
Rec_Dep7<-Rec_Dep5[which(Rec_Dep5$RecMake!="ATS SR3017" & 
                               Rec_Dep5$RecMake!="ATS 3017" &
                               Rec_Dep5$RecMake!="Tekno RT" &
                               Rec_Dep5$RecMake!="Tekno"),]

#Count receivers by Region
regs1<- dplyr::count(Rec_Dep7,Region)

#### may need to be updated
sac<- regs1[str_detect(regs1$Region, "^.*Sac"), ]
sac<- sac$n
delta <- regs1[str_detect(regs1$Region, "^.*Delta"), ]
delta<- delta$n
gg <- regs1[str_detect(regs1$Region, "SF Bay"), ]
gg<- gg$n
#mc<- subset(regs1, regs1$Region=="Mill Ck")
#mc<- mc$freq
sj<- subset(regs1, regs1$Region=="SanJoaquin_R")
sj<- sj$n
sr<- subset(regs1, regs1$Region=="Stanislaus R")
sr<- sr$n
```

There were `r nrow(Rec_Dep7)` autonomous receivers retrieved and/or deployed during this report period (Table 2). All acoustic receivers stationed in the Sacramento River, Delta, and Golden Gate were retrieved and deployed by UCSC. These locations include the lower Sacramento River (`r sac`), the San Joaquin River (`r sj`), the Stanislaus River (`r sr`) the south Delta (`r delta`), and Golden Gate (`r gg`).

```{r table2, echo=FALSE}

#Order table by StartTime
Rec_Dep7<-Rec_Dep7[order(as.Date(Rec_Dep7$StartTime, format="%d-%m-%Y")),]
#remove row numbers
rownames(Rec_Dep7) <- c()
#format SNs
Rec_Dep7$SN<- as.character(Rec_Dep7$SN)

#pipe data to table and give caption
RecDep7<- Rec_Dep7 %>%
    flextable() %>%
  set_caption("Table 2. Autonomous JSATS receivers deployed and retrieved during this report period") %>%
  font(fontname = "Times New Roman", part = "all") %>%
  fontsize(size = 11, part = "body") %>%
  width(width = .75)

#set table style
RecDep7<- theme_zebra(RecDep7, odd_header="#4472c4", odd_body ="#d9e2f3", even_header="transparent", even_body="transparent")
RecDep7<- border_outer(RecDep7, part="all", border= bord)
RecDep7<- border_inner(RecDep7, part="body", border=bord)
RecDep7<- align(RecDep7, align = "center", part = "all")

#print table
RecDep7
```

## Vemco Receiver Deployment

```{r callvm, echo=FALSE}

Vemco_Dep<-dbReadTable(con, "VemcoReceiverDeployments")

Vemco_Dep2<-subset(Vemco_Dep, select = c("GPSname", "VemcoSN", "StartTime", "EndTime"))


Vemco_Dep2$StartDate<-as.Date(Vemco_Dep2$StartTime, format = "%Y-%m-%d")
Vemco_Dep2$EndDate<-as.Date(Vemco_Dep2$EndTime, format = "%Y-%m-%d")


#Remove all 999 GPS name recievers
Vemco_Dep2<-Vemco_Dep2[which(Vemco_Dep2$GPSname!=999),]

######################################Edit below to change range of dates
#Get vemco deployments in range we're interested in
start<-Vemco_Dep2[Vemco_Dep2$StartDate >= begindate,]
start2<-start[start$StartTime <= enddate,]
end<-na.omit(Vemco_Dep2[which(Vemco_Dep2$EndTime >= begindate),])
end2<-end[end$EndTime <= enddate,]


#Add in active receivers not started in this quarter and remove 'active' receivers from previous year
a<-Vemco_Dep2[is.na(Vemco_Dep2$EndTime),]
end3<-rbind(end2,a)
end4<-end3[end3$StartTime >= begindate,]


#Make sure GPS names match
Vemco_Dep3<-unique(rbind(start2, end4))
#this introduces NA?
#remove NA GPSname
Vemco_Dep3= Vemco_Dep3[-1,]

test2<- left_join(Vemco_Dep3, Rec_Loc, by="GPSname")
notmatches2<- which(is.na(test2$GeneralLocation), arr.ind=TRUE)

###Add location to Vemco Receivers
#bring in site name and rkm data

vloc<-subset(Rec_Loc, select = c("GeneralLocation", "Genrkm", "GPSname"))

Vemco_Dep4<-merge(vloc,Vemco_Dep3, all.y = TRUE)


#Order table by start time
Vemco_Dep4<-Vemco_Dep4[order(as.Date(Vemco_Dep4$StartTime, format="%d-%m-%Y")),]

Vemco_Dep5<-Vemco_Dep4[,c("GPSname","GeneralLocation","Genrkm","VemcoSN","StartTime","EndTime")]
#remove row numbers
rownames(Vemco_Dep5) <- c()

```

UCSC deployed or retrieved `r nrow(Vemco_Dep5)` Vemco receivers between `r begindate` and `r enddate` (Table 3). All Golden Gate receivers were acoustic release style. These receivers are used to anchor JSATS receivers, but also serve a double purpose as a hydrophone for Vemco tags.

```{r table3, echo=FALSE}

#pipe data to table and give caption
VemDep5<- Vemco_Dep5%>%
  flextable() %>%
    set_caption(caption = "Table 3. Vemco receivers active, deployed, or retrieved during this report period") %>%
    font(fontname = "Times New Roman", part = "all") %>% 
    fontsize(size = 11, part = "body") %>%
    width(width = .75)

#set table style
VemDep5<- theme_zebra(VemDep5, odd_header="#4472c4", odd_body ="#d9e2f3", even_header="transparent", even_body="transparent")
VemDep5<- border_outer(VemDep5, part="all", border= bord)
VemDep5<- border_inner(VemDep5, part="body", border=bord)
VemDep5<- align(VemDep5, align = "center", part = "all")

#print table
VemDep5

```

## Deliverables:

1.  Provide data to ITAG JSATS Database coordinator and web-accessible autonomous receiver data (via ERDDAP) within 30 days of downloading
2.  Web-accessible semi-annual log of deployment and download activity including what sites were visited and operational coverage for each receiver

# Task 3. Source, obtain, and tag wild winter and spring-run Chinook salmon

```{r calltagged, echo=FALSE, warning=FALSE }
## download the tagged fish data set
library(plyr)
TaggedFish<- tbl(con, "TaggedFish") %>%
                   collect()

tag <- TaggedFish %>%
              mutate(DateTagged = as.POSIXct(DateTagged)) %>% #Format datetime
              mutate(Rel_datetime = as.POSIXct(Rel_datetime)) %>% #Format datetime
              filter(DateTagged >= as.POSIXct("2022-10-01 00:00:00")) #

#Summary table of studies and release dates
s<-unique(tag[,c("StudyID","DateTagged")])

```

```{r wildfish, echo=FALSE }

#Select studies to look at
tagbs<-tag[which(tag$StudyID=="ButteSink_2023"),]

butte<-unique(tagbs[,c("StudyID","Fish_Type","Raceway", "Rel_loc","DateTagged","Rel_datetime")])

tagbs$fish_number<-1

#Create summary table
tag_table<- plyr::ddply(tagbs, .(Raceway, DateTagged), summarise, count=sum(fish_number), meanW=mean(Weight), meanL=mean(Length), 
                 SD_W=sd(Weight), SD_L=sd(Length), min_W=min(Weight), min_L=min(Length),
                 max_W=max(Weight), max_L=max(Length))

#Set decimal place to 2
tag4<-as.data.frame(lapply(tag_table[sapply(tag_table, is.numeric)], round, 2))
#Add back in rel datetime row
tag4$DateTagged<-tag_table$DateTagged

tag5<-merge(tag4,butte)

tag5<-tag5[order(tag5$Rel_datetime),]

#Reduced table for report
tag6<-tag5[,c("StudyID", "Fish_Type", "Rel_loc", "Raceway", "count", "Rel_datetime", "meanW", "meanL")]
names(tag6)[names(tag6)=="Rel_loc"]<-"Release Loc"
names(tag6)[names(tag6)=="count"]<-"Count"
names(tag6)[names(tag6)=="Rel_datetime"]<-"Release Date"
names(tag6)[names(tag6)=="meanW"]<-"Avg Weight"
names(tag6)[names(tag6)=="meanL"]<-"Avg Length"
names(tag6)[names(tag6)=="Fish_Type"]<-"Fish Type"

buttetotal<- sum(tag6$Count)

```

```{r table5, echo=FALSE }
#pipe data to table and give caption
tag6<- tag6%>%
  flextable() %>%
    set_caption(caption = "Table 5. Wild Chinook acoustic tagged during this report period.") %>%
    font(fontname = "Times New Roman", part = "all") %>%
    fontsize(size = 11, part = "body") %>% 
    width(width = .75)

#set table style
tag6<- theme_zebra(tag6, odd_header="#4472c4", odd_body ="#d9e2f3", even_header="transparent", even_body="transparent")
tag6<- border_outer(tag6, part="all", border= bord)
tag6<- border_inner(tag6, part="body", border=bord)
tag6<- align(tag6, align = "center", part = "all")

#print table
tag6

```
UCSC staff implanted acoustic tags into `r buttetotal` wild-caught fish in the Sutter Bypass (Butte Creek) during this period.

## Deliverables:

1.  Final Pre-season tagging plan available via the website
2.  Web-accessible Telemetry Study Summary no more than 96 hours after the release of fish
3.  Annual technical report summarizing results from the previous study year
4.  Final report summarizing the results of the three study years
5.  One peer reviewed publication

# Task 4. Implant AT into a portion of hatchery produced juvenile Chinook salmon juveniles and Steelhead

## Acoustic Tagging of Chinook Salmon juveniles

UCSC staff implanted acoustic tags into hatchery produced jumpstart winter-run and late-fall run Chinook smolts as part of the Seasonal Survival Study. Releases of these fish were spaced out across six weeks between 12/13/2022 - 3/16/2023 with the intention of gathering movement and survival data across a range of environmental conditions during winter. These fish were tagged at Coleman, and Livingston Stone Fish Hatcheries and transported to the Red Bluff Diversion Dam (RBDD_Rel) to increase the sample size of fish in downstream reaches. In the case when the river was above flood stage, fish were released at ... Fish were available for tagging with the help and assistance of the U.S. Fish and Wildlife Service. The weekly release groups of tagged fish are shown in Table 5.

Preliminary movement and survival data can be found here: <https://oceanview.pfeg.noaa.gov/CalFishTrack/pageSeasSurv_2023.html>

```{r callfish, echo=FALSE }

###
#Edit below to change studies
###
#Select studies to look at
tagss<-tag[which(tag$StudyID=="Seasonal_Survival_2023"),]

s2<-unique(tagss[,c("StudyID","Fish_Type","Raceway", "Rel_loc","DateTagged","Rel_datetime")])

tagss$fish_number<-1

#Create summary table
tag_table<- plyr::ddply(tagss, .(Raceway, DateTagged), summarise, count=sum(fish_number), meanW=mean(Weight), meanL=mean(Length), 
                 SD_W=sd(Weight), SD_L=sd(Length), min_W=min(Weight), min_L=min(Length),
                 max_W=max(Weight), max_L=max(Length))

#Set decimal place to 2
tag4<-as.data.frame(lapply(tag_table[sapply(tag_table, is.numeric)], round, 2))
#Add back in rel datetime row
tag4$DateTagged<-tag_table$DateTagged

tag5<-merge(tag4,s2)

tag5<-tag5[order(tag5$Rel_datetime),]

#Reduced table for report
tag6<-tag5[,c("StudyID", "Fish_Type", "Rel_loc", "Raceway", "count", "Rel_datetime", "meanW", "meanL")]
names(tag6)[names(tag6)=="Rel_loc"]<-"Release Loc"
names(tag6)[names(tag6)=="count"]<-"Count"
names(tag6)[names(tag6)=="Rel_datetime"]<-"Release Date"
names(tag6)[names(tag6)=="meanW"]<-"Avg Weight"
names(tag6)[names(tag6)=="meanL"]<-"Avg Length"
names(tag6)[names(tag6)=="Fish_Type"]<-"Fish Type"

sstotal<- sum(tag6$Count)

```

```{r table5, echo=FALSE }
#pipe data to table and give caption
tag6<- tag6%>%
  flextable() %>%
    set_caption(caption = "Table 6. Hatchery fish acoustic tagged during this report period.") %>%
    font(fontname = "Times New Roman", part = "all") %>%
    fontsize(size = 11, part = "body") %>% 
    width(width = .75)

#set table style
tag6<- theme_zebra(tag6, odd_header="#4472c4", odd_body ="#d9e2f3", even_header="transparent", even_body="transparent")
tag6<- border_outer(tag6, part="all", border= bord)
tag6<- border_inner(tag6, part="body", border=bord)
tag6<- align(tag6, align = "center", part = "all")

#print table
tag6

```

## Acoustic Tagging of Juvenile Steelhead

Hatchery produced Steelhead were unable sourced and tagged at the Mokelumne River Hatchery during this report period. Instead, wild fish were sourced and tagged and released in the Stanislaus River with the assistance of the Department of Fish and Wildlife. These fish were part of a continuation of the "6 Year Study" aimed at estimating survival, routing and movement rates through the lower San Joaquin River and Delta during the spring outmigration period of San Joaquin River Basin Steelhead.

```{r, steel, echo=FALSE }
###Run this code for SJ Steelhead studies
###Remove Raceway
tag7<-tag[which(tag$StudyID=="Stan_Steelhead_2023"),]

s3<-unique(tag7[,c("StudyID","Fish_Type", "Rel_loc")])


tag7$fish_number<-1

#Create summary table
tag_table<-plyr::ddply(tag7, .(Rel_loc), summarise, count=sum(fish_number), meanW=mean(Weight), meanL=mean(Length), 
                 SD_W=sd(Weight), SD_L=sd(Length), min_W=min(Weight), min_L=min(Length),
                 max_W=max(Weight), max_L=max(Length))



#Set decimal place to 2
tag8<-as.data.frame(lapply(tag_table[sapply(tag_table, is.numeric)], round, 2))
#Add back in rel datetime row
tag8$Rel_loc<-tag_table$Rel_loc

tag9<-merge(tag8,s3)


#Reduced table for report
tag10<-tag9[,c("Rel_loc","StudyID", "Fish_Type", "count", "meanW", "meanL")]
names(tag10)[names(tag10)=="Rel_loc"]<-"Release Loc"
names(tag10)[names(tag10)=="Rel_loc"]<-"Release Loc"
names(tag10)[names(tag10)=="count"]<-"Count"
names(tag10)[names(tag10)=="Rel_datetime"]<-"Release Date"
names(tag10)[names(tag10)=="meanW"]<-"Avg Weight"
names(tag10)[names(tag10)=="meanL"]<-"Avg Length"
names(tag10)[names(tag10)=="Fish_Type"]<-"Fish Type"

```

```{r table6, echo=FALSE }
#pipe data into table and give caption
tag10<- tag10%>%
  flextable() %>%
    set_caption(caption = "Table 7. Wild Steelhead acoustic tagged during this study period") %>%
    font(fontname = "Times New Roman", part = "all") %>% 
    fontsize(size = 11, part = "body") %>% 
    width(width = .75)

#set table style
tag10<- theme_zebra(tag10, odd_header="#4472c4", odd_body ="#d9e2f3", even_header="transparent", even_body="transparent")
tag10<- border_outer(tag10, part="all", border= bord)
tag10<- border_inner(tag10, part="body", border=bord)
tag10<- align(tag10, align = "center", part = "all")

#print table
tag10

```

## Tag Retention Studies
```{r SStr, eval=FALSE, include=FALSE}
##format pit tags
options(scipen = 999)
#read in data from date tagged
SS_start<-read.csv("/Volumes/JRFREY_NOAA/SemiAnnReport/report2/Tag_Effects_Metadata.xlsx\ -\ Tag_Effects_Metadata.csv", header=TRUE)
#read in data from date dissection
#SS_end<-read.csv("/Volumes/JRFREY_NOAA/SemiAnnReport/SJ_Tag_Retention_2022_JRFworking.csv", header=TRUE)

#format colnames
SS_start2<- SS_start %>% dplyr::rename(Tag.ID = TagID_Hex, Pit_Tag = Notes)
#format dates
SS_start2$DateTagged<-as.Date(SS_start$DateTagged, format = "%d-%b-%y")
#create Date Shed column holder in SSstart2
SS_start2$Date.Shed<-as.Date(SS_start2$Date.Shed, format = "%d-%b-%y")

#format end data colnames
#SS_end2<- SS_end %>% dplyr::rename(weight_end = Weight, length_end = Length, Pit_Tag_end = Pit.Tag.ID)

#join by acoustic tag ID
#SS<-merge(SS_start2[,c("Tag.ID","Weight","Length","Pit_Tag")], SS_end2[,c("Tag.ID", "weight_end", "length_end", "Pit_Tag_end")], by.x = "Tag.ID", by.y = "Tag.ID", all.y = TRUE)

#Remove fish with no end weight/length
SS<-na.omit(SS)

#average weight gain
#g<- signif(mean(SS$weight_end-SS$Weight), 3)
g<- "x"
#average length growth
#l<- signif(mean(SS$length_end-SS$Length), 3)
l<- "y"

#tag bulge
#SS_b<- SS_end[which(SS_end$Tag.Bulge.Y.N == "Y"),]


#Collect shed tags
#SS_shed<-SS_start2[which(SS_start2$Tag.Shed.Y.N!="Y"),]

#SS_shed2<-SS_shed[,c("Tag.ID","Date.Shed")]
#SS_shed2$shed<-"Y"
#SS_shed2$shed2<-"Y"

```

### Seasonal Survival Tag Retention Study

As part of the Seasonal Survival Study, a total of `r sstotal` juvenile fall-run Chinook salmon were tagged at CNFH and LSNFH across three weeks (12/12/2022, 1/31/2023, and 3/14/2023) and transported to the NMFS-SWFSC lab where they were held on-site. The fish were fed and the tanks checked daily for expelled tags. Fish were measured and weighed at the start and end of the trial. At the end of the six week tag retention study, all fish were processed and inspected for shed tags. During this trial, no shed tags were found and all tags remained inside study fish.

Jesse needs the spreadsheet from dissections to calculate weight and length gain.


### San Joaquin Steelhead Tag Retention Study

Hatchery produced Steelhead were unable sourced and tagged at the Mokelumne River Hatchery during this report period. No wild-caught Steelhead were retained for tag retention studies.

## Tag Life Tests

```{r TLstart, echo = FALSE}
###Read in start up files
###Must be evaluated outside of script
start<- read.csv("/Volumes/JRFREY_NOAA/SemiAnnReport/report2/startupspecs.csv")
###

start<- start[,-1]
start$Date<- as.Date(start$Date,format = "%m/%d/%Y")
#Add in tag model and PRI columns to start up dataframe
# for week in seasonal survival study, apply tag model SS400
start$Tag_Model<-ifelse(start$Date %in% as.Date(tagss$DateTagged), "SS400", "Error")

#Remove blank tag IDs
start<-start[which(start$TagID!=""),]
#remove deactivated tag
start<- start[!grepl("DEACTIVATED", start$Notes),]

###Create Tag Model and warranty life dataframe
Tag_Model<-c("SS300","SS400","SS300 bat 392","SS300","SS400","SS300 bat 392","SS300","SS400","SS300 bat 392")
PRI<-c(3,3,3,5,5,5,10,10,10)
warranty_life<-c(23, 48, 79, 37, 71, 128, 68, 111, 238)
warranty<-data.frame(Tag_Model, PRI, warranty_life)

############################################################# THIS NEEDS TO BE FIXED
#Join tag model and PRI
start2<-merge(start, warranty, all.x = TRUE)
############################################################# THIS NEEDS TO BE FIXED
#hard fix
start2$warranty_life<- as.numeric('71')


#create warranty date col
start2$warranty_date<-as.Date(start2$Date, format = "%m/%d/%Y") + start2$warranty_life

#Create list of each study, use this to filter the detection data by study

SS_Wk1<-str_c(start2$TagID[which(as.Date(start$Date, format = "%m/%d/%Y")=="2022-12-13")], collapse = "|")
SS_Wk2<-str_c(start2$TagID[which(as.Date(start$Date, format = "%m/%d/%Y")=="2023-02-01")], collapse = "|")
SS_Wk3<-str_c(start2$TagID[which(as.Date(start$Date, format = "%m/%d/%Y")=="2023-03-01")], collapse = "|")
SS_Wk4<-str_c(start2$TagID[which(as.Date(start$Date, format = "%m/%d/%Y")=="2023-03-15")], collapse = "|")
```

### Seasonal Surival Tag Life Study

```{r ttab, warning=FALSE, echo= FALSE}

# Create Tag Life Tables --------------------------------------------------

###Read in tag inventory data for all studies
###Must be evaluated outside of script

inv<- read.csv("/Volumes/JRFREY_NOAA/SemiAnnReport/report2/tagspecs.csv")
start3<- read.csv("/Volumes/JRFREY_NOAA/SemiAnnReport/report2/start3.csv")
###

##Merge inventory with start up: add start date and PRI
start_inv<-left_join(start3, inv, by= c("TagID" = "HexCode"), keep=TRUE)

###create column for days on (Run one line or the other depending on if it has a timestamp)
start_inv$Date<-as.POSIXct(as.character(start_inv$Date, format = "%m/%d/%Y"))
start_inv$days_on_a<-difftime(start_inv$date_dead, start_inv$Date, units = "days")
start_inv$days_on<-format(round(start_inv$days_on_a, 1))
start_inv$days<- (as.numeric(str_extract(start_inv$days_on, ".*\\d" )))

#reduce
start_uni<-start_inv[,c("Date","HexCode","Tag_Model","ManufactureDate","PRI","date_dead","days_on", "days")]
#filter all tags by study

#tags started
tagcount<- nrow(start_uni)
#average tag life in days
avgrun<- signif(mean(start_uni$days),3)
#min tag life in days
mi<- signif(min(start_uni$days),3)
#max tag life in days
ma<- signif(max(start_uni$days),3)

#Tag Model SS400 @ PRI=5 has a warranty of 71 days
#number of tags that lasted to warranty or longer
n<- sum(start_uni$days >="71")

#Table format
start_uni<- rename(start_uni, c("Start Date" = "Date", "Hex Code" = "HexCode", 
                                   "Date Manufactured" = "ManufactureDate", "Tag Model" = "Tag_Model",
                                   "Period" = "PRI","Date Dead" = "date_dead", "Days on" = "days_on"))
start_uni<- start_uni[,-8]

#Reverse order of the table so that it matches the order of the plot
start_uni<-start_uni[nrow(start_uni):1,]

```

To monitor the battery life of the tags used for the Seasonal Survival Study, a 5% random sample was taken from the total proportion of tags used for each release group. In total, `r tagcount` SS400 tags were started over a period of 4 weeks (on 12/13/2022, 2/01/2023,3/01/2023, and 03/15/2023) and placed in the tag life tank located at the NMFS-SWFSC lab for monitoring. Data collected in this study examined the range of battery life for these particular tags, in order to correct any discrepancies in survival estimates as a result of tags shutting off prematurely. `r n` tags in the 2022 Seasonal Survival tag life study made it to the warranty life of 71 days. The average run time was `r avgrun` days with a range of `r mi` to `r ma` days.

#Tags started week 1:
12/13/2022 A total of 10 acoustic tags (model SS400) were randomly selected to be used in this tag life study. Tags were started on 12/13/2022 and placed into the tag life tank for the duration of the study. All tags in the RBDD Week 1 tag life study made it to the warranty life of 71 days and were detected consistently. 

```{r, w1, echo=FALSE}
png("pw1.png", width = 350, height = 350)
```

### San Joaquin Steelhead Tag Life Study

## Deliverables:

1.  Final Pre-season tagging plan available via the website
2.  Web-accessible Telemetry Study Summary no more than 96 hours after the release of fish
3.  Final memo/report on tag life results at end of year available via website
4.  Final memo/report on tag effects results at end of year available via website
5.  Annual technical report summarizing results from the previous study year
6.  Final report summarizing the results of the three study years
7.  Two peer reviewed publications

# Task 5. Produce and deliver real-time metrics

The project website was updated with new web pages describing unique tagging studies, including release metadata, travel time, number of fish detected at each real-time receiver, and detection efficiency for dual-line receiver locations (Sacramento, Benicia). <https://oceanview.pfeg.noaa.gov/CalFishTrack/>. Tagging data were updated two days after fish were tagged. Data from real-time receivers was automatically updated every hour.

## Deliverables:

1.  Website and email daily updates of arrival times, movement rates, and percent detected for each release group beginning immediately after the release of the first group.
2.  Website updated weekly with real-time data, summary statistics of real-time survival and routing, and predictions based on models fitted to historical late-fall Chinook data.

# Task 6. Project Management

Bi-weekly CVEAT conference calls and monthly ITAG virtual meetings were scheduled and moderated by ITAG facilitator Flora Cordoleani of UC Santa Cruz during the reporting period. These CVEAT calls facilitate close coordination on tagging events and receiver deployments between the many field operation leaders for the many different telemetry projects. Monthly ITAG meetings are for higher-level coordination and long-term planning for the Central Valley telemetry programs, and is attended by both field operation leaders as well as higher level agency representatives.

## Deliverables:

1.  Semi-annual progress reports
2.  The database coordinator will lead a data management workshop
3.  The database coordinator will participate in the ITAG meetings and appropriate subgroup meetings
4.  The database coordinator will work with agencies and stakeholders to address key data management questions
5.  The ITAG facilitator will schedule meetings and take meeting notes, and make meeting notes accessible to public via an online platform
6.  The ITAG facilitator will collect pre- and post-study summary forms from researchers and host them on the CalFishTrack website
7.  The ITAG facilitator will provide a summary report of ITAG activities within 6 months of the completion of the last ITAG tagging effort for the water year
